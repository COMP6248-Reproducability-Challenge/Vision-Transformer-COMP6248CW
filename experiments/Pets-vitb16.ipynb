{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d6f28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:37.656668Z",
     "start_time": "2022-04-26T23:27:30.441082Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torchbearer\n",
    "# from torchbearer import Trial\n",
    "# from torchbearer.callbacks import CosineAnnealingLR\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy\n",
    "\n",
    "from IPython.display import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f54a27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.362556Z",
     "start_time": "2022-04-26T23:27:37.661495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set dataset and model\n",
    "\n",
    "# Dataset\n",
    "dataset = torchvision.datasets.oxford_iiit_pet\n",
    "\n",
    "# Pre-trained models of ViT: \n",
    "# torchvision.models.vit_b_16/vit_b_32/vit_l_16/vit_l_32\n",
    "from torchvision.models import vit_b_16\n",
    "model = vit_b_16(pretrained=True)\n",
    "\n",
    "model_filename = \"pets-vitb16\"\n",
    "\n",
    "warmup_epoch = 5\n",
    "num_epoch = 7\n",
    "\n",
    "lr_warmup = 1e-3\n",
    "lr_base = 1e-2\n",
    "lr_min = 1e-3\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2221ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.378550Z",
     "start_time": "2022-04-26T23:27:40.366380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d493b358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.578169Z",
     "start_time": "2022-04-26T23:27:40.381732Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224)\n",
    "])\n",
    "train_set = torchvision.datasets.OxfordIIITPet(\"./data\", split= \"trainval\", download = True, transform=transform)\n",
    "test_set = torchvision.datasets.OxfordIIITPet(\"./data\", split= \"test\", download = True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729470f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.586362Z",
     "start_time": "2022-04-26T23:27:40.581834Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 如果Intel的Windows上matplotlib会导致内核重启就执行下这个\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# print(train_set[0][0].shape)\n",
    "# plt.imshow(train_set[0][0].permute(1,2,0).numpy()[:,:,::])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035725cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.615994Z",
     "start_time": "2022-04-26T23:27:40.590788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = model.heads[0].in_features\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502f062c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.653895Z",
     "start_time": "2022-04-26T23:27:40.620049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Linear(in_features=768, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.heads = nn.Linear(in_features, 37) # set in_features and out_features\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d923adb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:27:40.678382Z",
     "start_time": "2022-04-26T23:27:40.658325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze class_token\n",
      "Freeze conv_proj.weight\n",
      "Freeze conv_proj.bias\n",
      "Freeze encoder.pos_embedding\n",
      "Freeze encoder.layers.encoder_layer_0.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_0.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_0.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_0.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_0.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_0.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_0.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_0.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_0.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_0.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_0.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_0.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_1.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_1.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_1.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_1.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_1.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_1.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_1.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_1.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_1.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_1.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_1.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_1.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_2.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_2.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_2.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_2.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_2.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_2.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_2.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_2.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_2.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_2.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_2.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_2.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_3.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_3.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_3.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_3.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_3.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_3.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_3.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_3.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_3.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_3.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_3.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_3.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_4.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_4.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_4.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_4.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_4.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_4.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_4.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_4.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_4.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_4.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_4.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_4.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_5.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_5.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_5.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_5.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_5.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_5.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_5.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_5.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_5.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_5.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_5.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_5.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_6.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_6.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_6.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_6.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_6.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_6.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_6.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_6.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_6.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_6.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_6.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_6.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_7.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_7.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_7.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_7.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_7.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_7.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_7.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_7.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_7.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_7.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_7.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_7.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_8.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_8.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_8.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_8.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_8.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_8.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_8.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_8.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_8.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_8.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_8.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_8.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_9.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_9.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_9.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_9.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_9.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_9.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_9.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_9.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_9.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_9.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_9.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_9.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_10.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_10.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_10.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_10.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_10.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_10.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_10.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_10.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_10.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_10.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_10.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_10.mlp.linear_2.bias\n",
      "Freeze encoder.layers.encoder_layer_11.ln_1.weight\n",
      "Freeze encoder.layers.encoder_layer_11.ln_1.bias\n",
      "Unfreeze encoder.layers.encoder_layer_11.self_attention.in_proj_weight\n",
      "Unfreeze encoder.layers.encoder_layer_11.self_attention.in_proj_bias\n",
      "Unfreeze encoder.layers.encoder_layer_11.self_attention.out_proj.weight\n",
      "Unfreeze encoder.layers.encoder_layer_11.self_attention.out_proj.bias\n",
      "Freeze encoder.layers.encoder_layer_11.ln_2.weight\n",
      "Freeze encoder.layers.encoder_layer_11.ln_2.bias\n",
      "Freeze encoder.layers.encoder_layer_11.mlp.linear_1.weight\n",
      "Freeze encoder.layers.encoder_layer_11.mlp.linear_1.bias\n",
      "Freeze encoder.layers.encoder_layer_11.mlp.linear_2.weight\n",
      "Freeze encoder.layers.encoder_layer_11.mlp.linear_2.bias\n",
      "Freeze encoder.ln.weight\n",
      "Freeze encoder.ln.bias\n",
      "Unfreeze heads.weight\n",
      "Unfreeze heads.bias\n"
     ]
    }
   ],
   "source": [
    "# Freeze other layers unless it is self_attention or mlp_head\n",
    "for name, param in model.named_parameters():\n",
    "    if ('self_attention' in name) or ('head' in name):\n",
    "        print(\"Unfreeze \" + name)\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        print(\"Freeze \" + name)\n",
    "        param.requires_grad = False\n",
    "\n",
    "# optimiser1 = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "#                       lr=lr_warmup,\n",
    "#                       momentum=0.9) #only optimse non-frozen layers\n",
    "# optimiser2 = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "#                       lr=lr_base,\n",
    "#                       momentum=0.9) #only optimse non-frozen layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3696240a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:29:34.902563Z",
     "start_time": "2022-04-26T23:27:40.696778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading whole dataloader into memory can improve the speed of training\n",
    "train_loader = list(train_loader)\n",
    "test_loader = list(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f3eec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:29:34.921944Z",
     "start_time": "2022-04-26T23:29:34.912465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset OxfordIIITPet\n",
       "    Number of datapoints: 3680\n",
       "    Root location: ./data\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               CenterCrop(size=(224, 224))\n",
       "           )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48015142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:29:34.945147Z",
     "start_time": "2022-04-26T23:29:34.924774Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"model/\" + model_filename))\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# trial = Trial(model, optimiser2, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
    "# trial.with_generators(train_loader, test_generator=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e099b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:29:34.969558Z",
     "start_time": "2022-04-26T23:29:34.948401Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef312b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:29:40.180581Z",
     "start_time": "2022-04-26T23:29:34.972463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Linear(in_features=768, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = lr_base\n",
    "def adjust_learning_rate(optimizer, current_epoch, max_epoch, lr_min=lr_min, lr_max=lr_base, warmup=True):\n",
    "    if current_epoch < warmup_epoch:\n",
    "        lr = lr_max * (current_epoch+1) / (warmup_epoch+1)\n",
    "    else:\n",
    "        lr = lr_min + (lr_max-lr_min)*(1 + cos(pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    print(\"Learning rate is set to \"+str(lr))\n",
    "\n",
    "optimiser = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                      lr=lr,\n",
    "                      momentum=0.9) #only optimse non-frozen layers\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d99ce55a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:47.619377Z",
     "start_time": "2022-04-26T23:29:40.184322Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate is set to 0.0016666666666666668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec3b53a8f1f40b58bc727398a6a6157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch0):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf5n21/.conda/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/12:(tr)loss=149.3822\n",
      "epoch 0/12:(tr)acc=52.9620%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef51e6f6c814b3898af055286512697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test0:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf5n21/.conda/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/12:(te)loss=68.1411\n",
      "epoch 0/12:(te)acc=86.8084%\n",
      "Learning rate is set to 0.0033333333333333335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfd318023cf4805b319e7aca173dfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch1):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/12:(tr)loss=28.3853\n",
      "epoch 1/12:(tr)acc=92.0652%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22d679f012b49888a67965f01ce9ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test1:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/12:(te)loss=18.2046\n",
      "epoch 1/12:(te)acc=91.9052%\n",
      "Learning rate is set to 0.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc0e2368a2b4be3a9342032d8c97e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch2):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/12:(tr)loss=10.1133\n",
      "epoch 2/12:(tr)acc=96.5217%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a918c1f66240459f8322dab7a072f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test2:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/12:(te)loss=13.9588\n",
      "epoch 2/12:(te)acc=92.9681%\n",
      "Learning rate is set to 0.006666666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4bd17f6ccb4f948b8a912109a2de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch3):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/12:(tr)loss=4.8351\n",
      "epoch 3/12:(tr)acc=98.6956%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b62ece40a7c479787e697f3dd1f5f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test3:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/12:(te)loss=13.0617\n",
      "epoch 3/12:(te)acc=93.2407%\n",
      "Learning rate is set to 0.008333333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496063e8b45443abbf805008121c03ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch4):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/12:(tr)loss=2.2781\n",
      "epoch 4/12:(tr)acc=99.6467%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccae130e9464c1992295d7bb9d45e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test4:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/12:(te)loss=12.4159\n",
      "epoch 4/12:(te)acc=93.2134%\n",
      "Learning rate is set to 0.010000000000000002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f564b46101842c9b68c6e4871a2e963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch5):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/12:(tr)loss=1.7418\n",
      "epoch 5/12:(tr)acc=99.6467%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476a4036e5034948a8e8269f4610f82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test5:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/12:(te)loss=14.8412\n",
      "epoch 5/12:(te)acc=92.5048%\n",
      "Learning rate is set to 0.009554359905560885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938a5beccd034f689b803f4cb2470f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch6):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/12:(tr)loss=1.0423\n",
      "epoch 6/12:(tr)acc=99.9456%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32750d10b7ff4e3dad781b8d9c192bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test6:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/12:(te)loss=12.8244\n",
      "epoch 6/12:(te)acc=92.9954%\n",
      "Learning rate is set to 0.008305704108364302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c93723bb3c44c0c98ea496d00e47c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch7):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/12:(tr)loss=0.6145\n",
      "epoch 7/12:(tr)acc=99.9456%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f67fc4201ac46f980bff11b0b0fa56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test7:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/12:(te)loss=12.8934\n",
      "epoch 7/12:(te)acc=93.1316%\n",
      "Learning rate is set to 0.006501344202803416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2aedd1807be4b9eb2927eb1c578dd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch8):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/12:(tr)loss=0.3805\n",
      "epoch 8/12:(tr)acc=100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8cd8fe76e4316a7fba24e34bade4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test8:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/12:(te)loss=12.3675\n",
      "epoch 8/12:(te)acc=93.6768%\n",
      "Learning rate is set to 0.0044986557971965855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283621db5cc94cae9c0a9b101a83b37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch9):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/12:(tr)loss=0.3004\n",
      "epoch 9/12:(tr)acc=100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e45b1fe8ac4190be4ed9ba348b9d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test9:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/12:(te)loss=12.4907\n",
      "epoch 9/12:(te)acc=93.4314%\n",
      "Learning rate is set to 0.0026942958916356995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e932cf4703470c841286023e7dbf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch10):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/12:(tr)loss=0.2646\n",
      "epoch 10/12:(tr)acc=100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecab33e323e4e83ac031fc0177657c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test10:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/12:(te)loss=12.5313\n",
      "epoch 10/12:(te)acc=93.4042%\n",
      "Learning rate is set to 0.0014456400944391143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff50090f0d5846c28334dca68ad16be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train(epoch11):   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11/12:(tr)loss=0.2514\n",
      "epoch 11/12:(tr)acc=100.0000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb0ab1e0fc84e1bbc63e87b50fb09ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test11:   0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11/12:(te)loss=12.5556\n",
      "epoch 11/12:(te)acc=93.4587%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for epoch in range(warmup_epoch+num_epoch):\n",
    "    running_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    adjust_learning_rate(optimizer=optimiser,\n",
    "                        current_epoch=epoch,\n",
    "                        max_epoch=warmup_epoch+num_epoch)\n",
    "    with tqdm(train_loader, desc='Train(epoch'+str(epoch)+')') as t:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for data in t:\n",
    "            model.train()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            pred = torch.argmax(F.softmax(outputs), dim=1)\n",
    "            total += len(labels)\n",
    "            correct += sum(pred == labels)\n",
    "            \n",
    "        train_acc = (100.0 * correct) / total\n",
    "\n",
    "        t.set_postfix(running_loss=running_loss,\n",
    "                      runing_acc=train_acc)\n",
    "            \n",
    "    print(\"epoch %d/%d:(tr)loss=%.4f\" % (epoch, warmup_epoch+num_epoch, running_loss))\n",
    "    print(\"epoch %d/%d:(tr)acc=%.4f%%\" % (epoch, warmup_epoch+num_epoch, train_acc))\n",
    "    \n",
    "    test_running_loss = 0\n",
    "    test_acc = 0\n",
    "            \n",
    "    with tqdm(test_loader, desc='test'+str(epoch)) as t:\n",
    "        with torch.no_grad():\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for data in t:\n",
    "                model.eval()\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = loss_function(outputs, labels)\n",
    "                test_running_loss += loss.item()\n",
    "\n",
    "                pred = torch.argmax(F.softmax(outputs), dim=1)\n",
    "                total += len(labels)\n",
    "                correct += sum(pred == labels)\n",
    "            test_acc = (100.0 * correct) / total\n",
    "\n",
    "            t.set_postfix(running_loss=test_running_loss,\n",
    "                          runing_acc=test_acc)\n",
    "\n",
    "        print(\"epoch %d/%d:(te)loss=%.4f\" % (epoch, warmup_epoch+num_epoch, test_running_loss))\n",
    "        print(\"epoch %d/%d:(te)acc=%.4f%%\" % (epoch, warmup_epoch+num_epoch, test_acc))\n",
    "          \n",
    "    results.append({'running_loss':running_loss,\n",
    "                   'train_acc':train_acc,\n",
    "                   'test_running_loss':test_running_loss,\n",
    "                   'test_acc':test_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e06d91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:47.652562Z",
     "start_time": "2022-04-26T23:43:47.624638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'running_loss': 149.3821873664856,\n",
       "  'train_acc': tensor(52.9620, device='cuda:3'),\n",
       "  'test_running_loss': 68.14106714725494,\n",
       "  'test_acc': tensor(86.8084, device='cuda:3')},\n",
       " {'running_loss': 28.385265588760376,\n",
       "  'train_acc': tensor(92.0652, device='cuda:3'),\n",
       "  'test_running_loss': 18.204610288143158,\n",
       "  'test_acc': tensor(91.9052, device='cuda:3')},\n",
       " {'running_loss': 10.11327900737524,\n",
       "  'train_acc': tensor(96.5217, device='cuda:3'),\n",
       "  'test_running_loss': 13.958847381174564,\n",
       "  'test_acc': tensor(92.9681, device='cuda:3')},\n",
       " {'running_loss': 4.8350886926054955,\n",
       "  'train_acc': tensor(98.6956, device='cuda:3'),\n",
       "  'test_running_loss': 13.061653949320316,\n",
       "  'test_acc': tensor(93.2407, device='cuda:3')},\n",
       " {'running_loss': 2.2781197065487504,\n",
       "  'train_acc': tensor(99.6467, device='cuda:3'),\n",
       "  'test_running_loss': 12.415874730795622,\n",
       "  'test_acc': tensor(93.2134, device='cuda:3')},\n",
       " {'running_loss': 1.7417903067544103,\n",
       "  'train_acc': tensor(99.6467, device='cuda:3'),\n",
       "  'test_running_loss': 14.84124767780304,\n",
       "  'test_acc': tensor(92.5048, device='cuda:3')},\n",
       " {'running_loss': 1.042349035385996,\n",
       "  'train_acc': tensor(99.9456, device='cuda:3'),\n",
       "  'test_running_loss': 12.824388466775417,\n",
       "  'test_acc': tensor(92.9954, device='cuda:3')},\n",
       " {'running_loss': 0.6144982161931694,\n",
       "  'train_acc': tensor(99.9456, device='cuda:3'),\n",
       "  'test_running_loss': 12.893374118953943,\n",
       "  'test_acc': tensor(93.1316, device='cuda:3')},\n",
       " {'running_loss': 0.3805104282218963,\n",
       "  'train_acc': tensor(100.0000, device='cuda:3'),\n",
       "  'test_running_loss': 12.367455448955297,\n",
       "  'test_acc': tensor(93.6768, device='cuda:3')},\n",
       " {'running_loss': 0.30039924336597323,\n",
       "  'train_acc': tensor(100.0000, device='cuda:3'),\n",
       "  'test_running_loss': 12.490736972540617,\n",
       "  'test_acc': tensor(93.4314, device='cuda:3')},\n",
       " {'running_loss': 0.2645904887467623,\n",
       "  'train_acc': tensor(100.0000, device='cuda:3'),\n",
       "  'test_running_loss': 12.531278930604458,\n",
       "  'test_acc': tensor(93.4042, device='cuda:3')},\n",
       " {'running_loss': 0.2513958401978016,\n",
       "  'train_acc': tensor(100.0000, device='cuda:3'),\n",
       "  'test_running_loss': 12.55557744950056,\n",
       "  'test_acc': tensor(93.4587, device='cuda:3')}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e64d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "858a1dba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:52.768619Z",
     "start_time": "2022-04-26T23:43:47.654980Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/\" + model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ce3380a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:52.775331Z",
     "start_time": "2022-04-26T23:43:52.771697Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "for result in results:\n",
    "    train_loss_list.append(result[\"running_loss\"])\n",
    "    train_acc_list.append(torch.Tensor.cpu(result[\"train_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a383fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:52.804083Z",
     "start_time": "2022-04-26T23:43:52.776770Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "for result in results:\n",
    "    test_loss_list.append(result[\"test_running_loss\"])\n",
    "    test_acc_list.append(torch.Tensor.cpu(result[\"test_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bdb656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:52.831516Z",
     "start_time": "2022-04-26T23:43:52.805498Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 如果Intel的Windows上matplotlib会导致内核重启就执行这个\n",
    "# import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "812f96fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T23:43:53.292430Z",
     "start_time": "2022-04-26T23:43:52.833303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "ax[0].plot(train_loss_list)\n",
    "ax[0].plot(test_loss_list)\n",
    "ax[0].legend(['train','test'])\n",
    "ax[0].grid()\n",
    "ax[0].set_title(\"Loss\")\n",
    "\n",
    "ax[1].plot(train_acc_list)\n",
    "ax[1].plot(test_acc_list)\n",
    "ax[1].legend(['train','test'])\n",
    "ax[1].grid()\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8602f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e68f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78385b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ccfde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
